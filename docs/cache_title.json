{"_default": {"1": {"path": "/README.md", "hash": "ba64e0e8280c8973ad419f1fe5a8526f", "title": "Q-Transformer: Scalable Offline RL Model"}, "2": {"path": "/README.md:1-44", "hash": "9c70757152a0cf5e5cb9c510cc5dd010", "title": "Q-Transformer Package Installation and Usage"}, "3": {"path": "/README.md:45-86", "hash": "4b861a4c75577e7bcbc52f0c7d1cafd7", "title": "Mock Environment and QLearner Integration"}, "4": {"path": "/README.md:88-111", "hash": "c3e1523e408967a33e83dfd2b845d5bd", "title": "Video-Based Model: Optimal Actions from Instructions"}, "5": {"path": "/README.md:111-125", "hash": "1643624067477f63cef1b0babe7f1efc", "title": "Encoder-Decoder Model with Attention and Gating"}, "6": {"path": "/README.md:127-138", "hash": "63cb06dd41600f7916ecd3b10aa56a18", "title": "Q-Transformer: Enhancements and Experiments"}, "7": {"path": "/README.md:139-152", "hash": "159ec673949c093bf36892fce4b96d5f", "title": "BibTeX Entries for Publications"}, "8": {"path": "/q_transformer/__init__.py", "hash": "549dbe6a15ca617d91d70c3dfaacc132", "title": "Transformer-Based RL Architecture"}, "9": {"path": "/q_transformer/agent.py", "hash": "cf78e56e2d548ac6f651ddc2eb14db41", "title": "Q-Transformer Agent Training: Reinforcement Learning Experience"}, "10": {"path": "/q_transformer/agent.py:1-48", "hash": "d0dd2cc2890d19d87b8f26609049d433", "title": "Replay Memory Dataset Class Creation"}, "11": {"path": "/q_transformer/agent.py:49-72", "hash": "f0be8bf376837a37e9ef1fbf4ad4cb9b", "title": "Agent Attribute Initialization"}, "12": {"path": "/q_transformer/agent.py:74-99", "hash": "9e879a9a09193b6493193e0991627949", "title": "Training Episodes Based on Timesteps"}, "13": {"path": "/q_transformer/agent.py:101-129", "hash": "eaf50f6dfa4a4b302969a7041d94c613", "title": "BaseEnvironment Class Definition"}, "14": {"path": "/q_transformer/agent.py:131-168", "hash": "d0404765488bf0b1b919175fe9bbaa64", "title": "Agent Initializes with QRoboticTransformer"}, "15": {"path": "/q_transformer/agent.py:170-197", "hash": "6c5a91c4280ddc143cd3276d64cda57a", "title": "Q-Transformer Agent Initialization"}, "16": {"path": "/q_transformer/agent.py:198-214", "hash": "7542e330e9212fe04d82dba54de7aef6", "title": "Epsilon Scheduling in Q-Transformer Agent"}, "17": {"path": "/q_transformer/agent.py:216-248", "hash": "4475c05767686ffaa55cd4c24c83c67f", "title": "Q-Transformer Agent Interactions"}, "18": {"path": "/q_transformer/agent.py:249-274", "hash": "ecd9d8f9d37db062e6a3bca221304ebf", "title": "Reinforcement Learning Agent Memory Storage"}, "19": {"path": "/q_transformer/attend.py", "hash": "90f037a42c69bed86a4aed1dd79b5e6e", "title": "Attention-Based PyTorch Network Operations"}, "20": {"path": "/q_transformer/attend.py:1-58", "hash": "6b8ac0207b17e48247c62197c1ab64ca", "title": "Attention-based Neural Network Module"}, "21": {"path": "/q_transformer/attend.py:59-86", "hash": "577c7c6f3b0dd93485dbd4b70ac30d29", "title": "Flash Attention Dropout Self-Attention Class"}, "22": {"path": "/q_transformer/attend.py:87-123", "hash": "71475c5a9dd3af59ae38fff1a9542604", "title": "Scaled Dot Product Attention with Causality"}, "23": {"path": "/q_transformer/attend.py:124-145", "hash": "bacc3fa047056bfd44036eb8e7ae9e90", "title": "Soft Attention Masking"}, "24": {"path": "/q_transformer/mocks.py", "hash": "421de7b2634c421d65680282613e5c00", "title": "Q-Transformer Mock Environments"}, "25": {"path": "/q_transformer/mocks.py:1-38", "hash": "4c781d6da0c27d2027995c64bfb4a9a0", "title": "Mock Environment for Q-Transformer Model"}, "26": {"path": "/q_transformer/mocks.py:39-73", "hash": "95d345467e887af178ae1d4d364fe2ee", "title": "MockReplayNStepDataset: Custom Dataset for RL Agents Training"}, "27": {"path": "/q_transformer/mocks.py:74-91", "hash": "daf2f3c06ea50a65de6ae33db3f6946d", "title": "Custom Dataloader for RL Tasks"}, "28": {"path": "/q_transformer/optimizer.py", "hash": "9a6ae1601f05cdc7b778d5891aee07b5", "title": "Weight Decay Optimizer Functions"}, "29": {"path": "/q_transformer/q_learner.py", "hash": "c74013515ef8b8f6ebf1ab310e450fa4", "title": "Robotic Q-Learner for Transformers"}, "30": {"path": "/q_transformer/q_learner.py:1-47", "hash": "3f7b5726601d516923355de27777951f", "title": "Q-Learner: QIntermediates and Losses"}, "31": {"path": "/q_transformer/q_learner.py:49-92", "hash": "9e3a2a2b3025593713672fac6f3f4364", "title": "QLearner for Robotic Transformers: Reinforcement Learning and Rewards"}, "32": {"path": "/q_transformer/q_learner.py:93-126", "hash": "a880ee814f25840f0380ceb1b77cef79", "title": "Q-Learner Class in Reinforcement Learning"}, "33": {"path": "/q_transformer/q_learner.py:128-169", "hash": "b81e8da804160a38e24344b801f5a219", "title": "Initializing Q Learner Components and Accelerator"}, "34": {"path": "/q_transformer/q_learner.py:170-210", "hash": "0d7eb027f9271b6a3501147398b361e8", "title": "QTransformer Model Initialization and Training Setup"}, "35": {"path": "/q_transformer/q_learner.py:211-248", "hash": "d5feac928a692f3334b88e426b54a25c", "title": "Q Learner Class Methods"}, "36": {"path": "/q_transformer/q_learner.py:250-274", "hash": "5a31e2efc0361cc5da47a137ba9ee0ec", "title": "Q-Learner Class and Q Transformer"}, "37": {"path": "/q_transformer/q_learner.py:275-297", "hash": "f8437f1501152decd5dcd924593e5b6a", "title": "Q-Learning Algorithm: Smooth Model, Bellman Equation, MSE Loss"}, "38": {"path": "/q_transformer/q_learner.py:299-334", "hash": "f76146bfaf39b07b577fa2f7aa84262c", "title": "N-Step Q-Learning on Embedding Data"}, "39": {"path": "/q_transformer/q_learner.py:336-366", "hash": "d24dca56aa53a2c152df68723fd06b0e", "title": "Discounted Q-value Calculation and Learning"}, "40": {"path": "/q_transformer/q_learner.py:368-403", "hash": "887a44b315adbf7d479a6af302c17e31", "title": "Autoregressive Q-Learner Function"}, "41": {"path": "/q_transformer/q_learner.py:405-438", "hash": "f3fc1afa83ec8b21faff0fac84077d1a", "title": "Update Q-values with Monte Carlo Method"}, "42": {"path": "/q_transformer/q_learner.py:440-470", "hash": "482f8a673eb1d9ea69f068cbf446c2da", "title": "Q-Learning Text Embeddings Algorithm"}, "43": {"path": "/q_transformer/q_learner.py:472-495", "hash": "df98f68544eebcd52295cc9f3a5c830a", "title": "Q-Value Calculation and Clamping"}, "44": {"path": "/q_transformer/q_learner.py:497-526", "hash": "75369cc490da3af36fcd02b6d5f8b1a3", "title": "Q-Learner: Multi-Step Q-Learning Implementation"}, "45": {"path": "/q_transformer/q_learner.py:528-555", "hash": "c72c17ed42320e8b942fa283d87ca7b9", "title": "Conservative Regularized Q-Learning Algorithm"}, "46": {"path": "/q_transformer/q_learner.py:557-593", "hash": "2e070d82fd20e741399ae9477d338b8e", "title": "QLearner: Combining TD Loss and Conservative Regularization"}, "47": {"path": "/q_transformer/q_learner.py:594-631", "hash": "a5893800736998559b0bdbbf03771d80", "title": "Asynchronous Sync-Free Q Learner Training"}, "48": {"path": "/q_transformer/q_learner.py:632-637", "hash": "b4bfb697ba89074e4341539acad05536", "title": "Training Completes Every Checkpoint"}, "49": {"path": "/q_transformer/q_robotic_transformer.py", "hash": "e77348d790a870f50dd45d61db1e3a55", "title": "Q-Transformer for Robotic Actions"}, "50": {"path": "/q_transformer/q_robotic_transformer.py:1-44", "hash": "b137f99cd29da4bc01518b2018449336", "title": "Utility Functions for Robotic Transformers"}, "51": {"path": "/q_transformer/q_robotic_transformer.py:46-78", "hash": "b6b026d88996969315e50f17426ec3c7", "title": "Rotary Embeddings for 2D Positions"}, "52": {"path": "/q_transformer/q_robotic_transformer.py:79-114", "hash": "b9b256f2d2d73329ab372422863e5b3d", "title": "Batch Normalization Functions and Layers"}, "53": {"path": "/q_transformer/q_robotic_transformer.py:116-155", "hash": "3a121114c0c039f8704a00120c782c72", "title": "Posemb Sincos Function"}, "54": {"path": "/q_transformer/q_robotic_transformer.py:156-198", "hash": "cbe8b14ba1a5419b961ee459f5b2de0d", "title": "MBConv Residual Block for CNNs"}, "55": {"path": "/q_transformer/q_robotic_transformer.py:200-242", "hash": "349798cf3d6692e1aa2a49796da7fd03", "title": "Robotic Transformer with DropSampling and MBConv Block"}, "56": {"path": "/q_transformer/q_robotic_transformer.py:243-288", "hash": "31da6b29b737f32568779be6fdd4516f", "title": "Residual Convolutional Attention Network"}, "57": {"path": "/q_transformer/q_robotic_transformer.py:289-332", "hash": "9542e89294a2254560e53f080b452d5a", "title": "Multi-Head QTransformer with Gate"}, "58": {"path": "/q_transformer/q_robotic_transformer.py:334-374", "hash": "0d8dd21666f570312bd847c1d79c49a6", "title": "MaxViT Initialization in Robotic Transformer"}, "59": {"path": "/q_transformer/q_robotic_transformer.py:376-405", "hash": "c02626bb1c03b66c791a09591bf21ec9", "title": "MaxViT Module Initialization"}, "60": {"path": "/q_transformer/q_robotic_transformer.py:406-418", "hash": "4d9c6c9afb93d6a17649d1e7e99a4b79", "title": "Multi-Operation Neural Layer with Q-Transformer"}, "61": {"path": "/q_transformer/q_robotic_transformer.py:419-462", "hash": "dabf891862bade81087269f9adc969f9", "title": "Robotic Q-Transformer Model"}, "62": {"path": "/q_transformer/q_robotic_transformer.py:463-507", "hash": "d4fe32ba34e897a127e0cace172d59d5", "title": "Robotic Transformer with Window and Grid Attention"}, "63": {"path": "/q_transformer/q_robotic_transformer.py:508-545", "hash": "fe3c197a6093e9db20945dd8aaba8363", "title": "Memory-Aware Q Robotic Transformer"}, "64": {"path": "/q_transformer/q_robotic_transformer.py:547-580", "hash": "d7868ecf3bf8101bded32070d5aebd5b", "title": "Q-Transformer: Query Processing Layer"}, "65": {"path": "/q_transformer/q_robotic_transformer.py:582-621", "hash": "de802d5604a7008d3fa9165bdfec7902", "title": "Customizable Transformer Attention Layers"}, "66": {"path": "/q_transformer/q_robotic_transformer.py:622-660", "hash": "1d9469c138e586a6b9c0739128de3d21", "title": "Transformer Layer Forward Pass"}, "67": {"path": "/q_transformer/q_robotic_transformer.py:661-701", "hash": "18268cb116ff46ef842a1adefe994d8f", "title": "Robotic Attention Transformer Model"}, "68": {"path": "/q_transformer/q_robotic_transformer.py:702-744", "hash": "e4b81797c9bf7edd918a5e9978c6387a", "title": "Robotic Q-Transformer Model with Dueling Head"}, "69": {"path": "/q_transformer/q_robotic_transformer.py:745-782", "hash": "38a76d0ea63f0740ed3cece451f2c6df", "title": "QHeadSingleAction Class for Neural Networks"}, "70": {"path": "/q_transformer/q_robotic_transformer.py:783-822", "hash": "d82ab0f49fdea93b8ade20b748d234ee", "title": "QHeadMultipleActions: Robotic Transformer Q-Values"}, "71": {"path": "/q_transformer/q_robotic_transformer.py:823-854", "hash": "1416b30cac6e5a8447583e48724a58a8", "title": "Initializing Q Robotic Transformer Model"}, "72": {"path": "/q_transformer/q_robotic_transformer.py:856-879", "hash": "3ae583c3cd16ecd7fcae160f84c74343", "title": "Random Action Generator"}, "73": {"path": "/q_transformer/q_robotic_transformer.py:880-914", "hash": "8a4eaa9c99739523e8426a588bf07f00", "title": "Efficient Robotic Transformer for Optimal Actions"}, "74": {"path": "/q_transformer/q_robotic_transformer.py:915-944", "hash": "99c47155d4cc6f9a0264382e55863ff9", "title": "Q-Value Calculation for Robotic Transformer Actions"}, "75": {"path": "/q_transformer/q_robotic_transformer.py:945-988", "hash": "c12ca3364177ed76ac9b6245ed9c7b1a", "title": "QRoboticTransformer: Q-Value Prediction for Robotic Tasks"}, "76": {"path": "/q_transformer/q_robotic_transformer.py:989-1028", "hash": "5fcee17062ea35e30ed91c3f71ed1296", "title": "Robotic Vision Transformer Model"}, "77": {"path": "/q_transformer/q_robotic_transformer.py:1029-1062", "hash": "baff6e91a01093dd44f02efcb203c598", "title": "Robotic Transformer Model: QHead & Adaptive Normalization"}, "78": {"path": "/q_transformer/q_robotic_transformer.py:1063-1096", "hash": "365343c1ec9631a26bf023e23696fb13", "title": "Q-Transformer Robotic Model with Multi-Action Predictions"}, "79": {"path": "/q_transformer/q_robotic_transformer.py:1098-1134", "hash": "d575841a0eb56ab8fb6d28719c48d38f", "title": "Robotic Transformer: Action Selection and State Encoding"}, "80": {"path": "/q_transformer/q_robotic_transformer.py:1134-1161", "hash": "6a518fcfecdab7c49071aad1d01b9243", "title": "Conditional Vision Transformer for Robotics"}, "81": {"path": "/q_transformer/q_robotic_transformer.py:1162-1189", "hash": "a4caebb67c0c765cd51c1c1cd493041a", "title": "Token Unpacking and Transformer Attention"}, "82": {"path": "/q_transformer/q_robotic_transformer.py:1190-1216", "hash": "dc9894c1ea6cbc660e75d2c7851b971e", "title": "Robotic Transformer Q-values Calculation"}, "83": {"path": "/setup.py", "hash": "0c6c011581dab897ceeae7aa9b2c11ad", "title": "Setting Up Q-Transformer"}}}